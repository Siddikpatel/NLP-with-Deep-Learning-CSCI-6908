{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pamYYEdspT4E"
   },
   "source": [
    "# CSCI6908: Assignment 4 - GPT from Scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Deadline: Monday, March 17th, 2025</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJoKdFfdpjDd"
   },
   "source": [
    "# Part 0: Introduction\n",
    "\n",
    "During the lecture, you have covered the Transformers architecture. Such architecture represents the backbone of many state-of-the-art large language models. In this assignment you will implement from scratch a Generative Pre-trained Transformer (GPT) model, which is nothing but a decoder-only Transformer. You will implement from scratch using `pytorch` the different building blocks that constitute the GPT model.  \n",
    "\n",
    "This assignment assumes some familiarity with the framework. You can consult `pytorch`'s [documentation](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) to brush up on your knowledge.  \n",
    "\n",
    "The main goals of this assignment are:  \n",
    "  - Implement the Causal Self-Attention layer and use it to form the Multihead-Attention block.\n",
    "  - Implement contemporary activation functions used in modern day language models.\n",
    "  - Implement the GPT model and its subcomponents.\n",
    "  - Pre-train a generative model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Requirements\n",
    "Before you can start, make sure you install the dependencies list in the `requirements.txt` file. It is advised that you use a Python virtual enviornment. You can consult how you can a add virtual enviornment to Jupyter's kernal through this [guide](https://janakiev.com/blog/jupyter-virtual-envs/).  \n",
    "In this assignment you will train a GPT model for a duration of at least $20K$ steps (not epochs). If you do not have access to enough computational resources here are your options:\n",
    "- Use a configuration that yields a smaller GPT model. For instance, use only $4$ layers instead of $6$.\n",
    "- Use [Google Colab](https://colab.research.google.com/).\n",
    "- Use Dal's Brookside and Calvert [servers](https://www.dal.ca/faculty/computerscience/for-faculty-staff/technical-services.html). Check under _Academic compute enviornment_ > _GPU Processing_. There you will find links that redirect you to the Jupyter lab interface hosted on these servers.\n",
    "\n",
    "**Please note that your grade will depend on the implementation and not on the running results. Hence, if you cannot train these models fully, you can still get the full grade if your implementation is correct.**\n",
    "\n",
    "## Submission Guidelines\n",
    "Add the TA as _Maintainer_ to your fork and submit your fork's URL on Brightspace. Push the modifications you have made on this notebook to your fork.  \n",
    "\n",
    "## Submission of SDAs\n",
    "For this assignment, SDAs should be submitted through Brightspace. You will find the submission box under _Assignments_ > _SDA_. **<span style=\"color:red\">Please note that you are only allowed to submit 2 SDAs for this course. Hence, if you already reached that limit, you can no longer submit one. In addition, no SDA will be considered if sent by email. All SDAs should be submitted through Brightspace at least 24 hours prior to the deadline. The PDF file should be following this format: `<BANNER-ID>_<FIRST-NAME>_<LAST_NAME>_<ASSIGNMENT-NUMBER>.pdf`</span>**  \n",
    "\n",
    "If you have any questions, please do not hesitate to post them on the courseâ€™s Teams channel. If you have not joined already, you can do so by using this code: `ot45hmp`.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzWbGllPrhYU"
   },
   "source": [
    "## Part 1: Multihead-Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd3ZZZNjtrYR"
   },
   "source": [
    "<center><img src=\"https://production-media.paperswithcode.com/methods/multi-head-attention_l1A3G7a.png\" align=\"center\" width=\"350px\">\n",
    "</center>\n",
    "Source: Vaswani *et al.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_po2Hx3Z2Yb"
   },
   "source": [
    "### Part 1.1: Causal Self-attention Layer:\n",
    "\n",
    "The Causal Self-attention layer is a fundamental building block of the GPT (Generative Pre-trained Transformer) architecture. This layer consists of several key components that work together to enable the model to focus on relevant parts of the input sequence while maintaining the autoregressive property. The main components of a causal self-attention head are:  \n",
    "\n",
    "\n",
    "1. Linear projections: Three separate linear transformations are applied to the input to create the query ($Q$), key ($K$), and value ($V$) matrices: $Q = XW_q, K = XW_k, V = XW_v$ where $X$ is the input tensor, and $W_q$, $W_k$, and $W_v$ are learnable weight matrices.\n",
    "\n",
    "2. Scaled dot-product attention: The attention mechanism is computed as: $\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}} + M\\right)V$ where $d_k$ is the dimensionality of the key vectors, and $M$ is the causal mask.\n",
    "\n",
    "3. Causal masking: A lower triangular matrix $M$ is applied to ensure that each token can only attend to itself and previous tokens: $M_{ij} = \\begin{cases} 0 & \\text{if } i \\geq j \\ -\\infty & \\text{if } i < j \\end{cases}$\n",
    "\n",
    "\n",
    "These components work together to create a causal self-attention mechanism that captures dependencies between tokens while respecting the sequential nature of the input, which is crucial for language modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "\n",
    "Complete the implementation of the `__init__` and `forward` functions of the `CausalSelfAttention`.  \n",
    "**Note that you are only allowed to use the following `pytorch` APIs: `nn.Linear`, `nn.Dropout`, `torch.softmax`/`nn.Softmax`. You are allowed to use all tensor operations such as .transpose(), .size() and so on**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XijKRDjdpRoR"
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "      \"\"\"\n",
    "      d_in: embedding dimension\n",
    "      d_out: embedding dimension\n",
    "      context_length: maxmimum number of tokens in the sequence\n",
    "      dropout: dropout rate\n",
    "      qkv_bias: flag to whether use bias for the query, key and value layers or not.\n",
    "      \"\"\"\n",
    "      super().__init__()\n",
    "      # Define the netowrk structure here\n",
    "      self.query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "      self.key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "      self.value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "      self.attn_dropout = nn.Dropout(dropout)\n",
    "      \n",
    "      self.register_buffer(\n",
    "          \"mask\", \n",
    "          torch.tril(torch.ones(context_length, context_length))\n",
    "      )\n",
    "      \n",
    "      self.d_out = d_out\n",
    "\n",
    "    def forward(self, x):\n",
    "      batch_size, seq_len, d_in = x.size()\n",
    "        \n",
    "      q = self.query(x) # (batch_size, seq_len, d_out)\n",
    "      k = self.key(x)   \n",
    "      v = self.value(x)  \n",
    "      \n",
    "      attn_scores = (q @ k.transpose(-2, -1)) / (self.d_out ** 0.5)\n",
    "    \n",
    "      causal_mask = self.mask[:seq_len, :seq_len]\n",
    "      \n",
    "      attn_scores = attn_scores.masked_fill(causal_mask == 0, float('-inf'))\n",
    "      \n",
    "      attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "      \n",
    "      attn_weights = self.attn_dropout(attn_weights)\n",
    "      \n",
    "      output = attn_weights @ v \n",
    "      \n",
    "      return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoBZo3eGAhas"
   },
   "source": [
    "### Part 1.2: Multihead Self-attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLsdTPMHBahA"
   },
   "source": [
    "Multihead Self-attention extends the concept of single-head attention by allowing the model to jointly attend to information from different representation subspaces at different positions. It enhances the model's capability to capture diverse relationships within the input sequence by employing multiple attention heads in parallel. Each head operates independently, allowing the model to focus on different aspects of the input simultaneously. The output of this layer is calculated as follows:\n",
    "\n",
    "$\\text{MultiHead}(X) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_h)W^O$\n",
    "\n",
    "Where $h$ is the number of attention heads, and $W^O \\in \\mathbb{R}^{hd_v \\times d_{model}}$ is the output projection matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "Complete the implementation of the `__init__` and `forward` functions of the `MultiHeadAttention` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jE4Ya62VAiDY"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "      \"\"\"\n",
    "      d_in: embedding dimension\n",
    "      d_out: embedding dimension of one attention head\n",
    "      context_length: maxmimum number of tokens in the sequence\n",
    "      dropout: dropout rate\n",
    "      num_heads: number of heads\n",
    "      qkv_bias: flag to whether use bias for the query, key and value layers or not.\n",
    "      \"\"\"\n",
    "      super().__init__()\n",
    "      # Define the netowrk structure here\n",
    "      self.num_heads = num_heads\n",
    "      self.d_out = d_out\n",
    "      \n",
    "      # Create multiple attention heads\n",
    "      self.heads = nn.ModuleList([\n",
    "          CausalSelfAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "          for _ in range(num_heads)\n",
    "      ])\n",
    "      \n",
    "      self.output_projection = nn.Linear(d_out * num_heads, d_in)\n",
    "      \n",
    "      self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "      head_outputs = [head(x) for head in self.heads]\n",
    "        \n",
    "      multihead_output = torch.cat(head_outputs, dim=-1)\n",
    "      \n",
    "      output = self.output_projection(multihead_output)\n",
    "      \n",
    "      output = self.dropout(output)\n",
    "      \n",
    "      return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4SLeZu8MR4-"
   },
   "source": [
    "Sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6EHk20REWfM",
    "outputId": "57e558dc-f000-452e-eb12-ea8f99e6b7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([1, 512, 256])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "vocab_size = 50257\n",
    "context_length = 512\n",
    "d_in = 256\n",
    "num_heads = 4\n",
    "d_out = d_in // num_heads\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads)\n",
    "\n",
    "sample_input = torch.randn(1, context_length, d_in)\n",
    "\n",
    "context_vecs = mha(sample_input)\n",
    "assert context_vecs.shape == (1, context_length, d_out * num_heads)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADzpN8rnwbcD"
   },
   "source": [
    "## Part 2: GELU Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmLpIkdhwlQc"
   },
   "source": [
    "The Gaussian Error Linear Unit (GELU) is an activation function that is used in modern Transformer-based models. Originally, Transformers used the Rectified Linear Unit (ReLU) as their activation function. This activation function is used in the Feedforward network that you will implement later in the assignment. GELU can be mathematically expressed as:\n",
    "\n",
    "$\\text{GELU}(x) = x \\cdot \\Phi(x)$\n",
    "\n",
    "where $\\Phi(x)$ is the cumulative distribution function of the standard normal distribution. In practice, we often use an approximation of GELU rather than the exact formula involving the CDF. This approximation is computationally more efficient and easier to implement, while still capturing the essential behavior of GELU. \n",
    "\n",
    "#### Tasks\n",
    "In the below code cell, complete the implementation of the `forward` method of the `GELU` activation function class using the first approxmiation formula given by [(Hendrycks and Gimpel, 2020)](https://arxiv.org/abs/1606.08415) (the one that that starts with $0.5x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0pTHdNZwMEF"
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iY2o3BjGxFc4"
   },
   "source": [
    "## Part 3: LayerNorm\n",
    "\n",
    "Layer Normalization (LayerNorm) is a crucial technique that stabilizes the learning process. It operates on the feature dimension. For an input $x \\in \\mathbb{R}^{d}$, LayerNorm is defined as:\n",
    "\n",
    "$\\text{LayerNorm}(x) = \\gamma \\odot \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta$\n",
    "\n",
    "where $\\mu = \\frac{1}{d}\\sum_{i=1}^d x_i$ is the mean, $\\sigma^2 = \\frac{1}{d}\\sum_{i=1}^d (x_i - \\mu)^2$ is the variance, $\\epsilon$ is a small constant for numerical stability (typically $10^{-5}$), $\\gamma$ and $\\beta$ are learnable scale and shift parameters respectively, and $\\odot$ denotes element-wise multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "Complete the implementation of the `__init__` and `forward` functions of the `LayerNorm` class.  \n",
    "**Hint:** In `pytorch`, `nn.Parameter` is used to defined learnbale parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DS4DVEpRwrsx"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Define the netowrk structure here\n",
    "        self.gamma = nn.Parameter(torch.ones(hidden_dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, unbiased=False, keepdim=True)\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * x_norm + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTmxjPvzz5VH"
   },
   "source": [
    "## Part 4: Feeforward Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wn5BPr44aLP"
   },
   "source": [
    "The Feedforward Network (FFN) is a main component in each Transformer block, applied after the MHA layer. It consists of two linear transformations with a non-linear activation function in between, which in modern implementations is often the Gaussian Error Linear Unit (GELU) that you implemented earlier. The FFN is expressed as:\n",
    "\n",
    "$\\text{FFN}(x) = \\text{GELU}(xW_1 + b_1)W_2 + b_2$\n",
    "\n",
    "where $x \\in \\mathbb{R}^{d_\\text{model}}$ is the input, $W_1 \\in \\mathbb{R}^{d_\\text{model} \\times d_\\text{ff}}$, $W_2 \\in \\mathbb{R}^{d_\\text{ff} \\times d_\\text{model}}$ are weight matrices, and $b_1, b_2$ are bias vectors. In your implementation make sure that $d_\\text{ff} = 4\\times d_\\text{model}$. For more clarity, $d_\\text{model}$ is also referred to as the hidden layer dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "Complete the implementation of the `__init__` and `forward` functions of the `FeeForward` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8hbX1bVxRwJ"
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        # Define the netowrk structure here\n",
    "        d_ff = 4 * d_in\n",
    "        self.fc1 = nn.Linear(d_in, d_ff)  \n",
    "        self.gelu = GELU()                \n",
    "        self.fc2 = nn.Linear(d_ff, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kldKnOB43wK8"
   },
   "source": [
    "## Part 5: The Transformer Layer and the GPT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIh1wFM_6MpP"
   },
   "source": [
    "At this stage, you have implemented all the building blocks that constitute the Transformer layer. Your task now is to assemble this layer using these blocks. Use the following illustration as a guideline to help you do so.\n",
    "<center><img src=\"https://i.imgur.com/TpHBi7y.png\" align=\"center\" width=\"250px\">\n",
    "</center>\n",
    "\n",
    "**N.B:** The Postional and Input Embedding layers are not part of the Transformer layer. You will later define those when building the GPT model. **In addition, although the figure taken from the work of Vaswani et. al show a softmax layer at the end, the implementation of the GPT model should NOT include it. The reason is the loss function that will be used to pre-train the model accepts logits and then applies softmax. Hence, if you apply softmax, you would be applying it twice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the implementation of the `__init__` and `forward` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ar6KZZK_0GLD"
   },
   "outputs": [],
   "source": [
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, num_heads ,dropout):\n",
    "        super().__init__()\n",
    "        # Define the netowrk structure here: MHA, FFNN, LayerNorm1, LayerNorm2\n",
    "        head_dim = d_in // num_heads\n",
    "        \n",
    "        self.ln1 = LayerNorm(d_in)\n",
    "        self.ln2 = LayerNorm(d_in)\n",
    "        \n",
    "        self.attention = MultiHeadAttention(\n",
    "            d_in=d_in,\n",
    "            d_out=head_dim,\n",
    "            context_length=context_length,\n",
    "            dropout=dropout,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "        \n",
    "        self.feedforward = FeedForward(d_in=d_in, d_out=d_out)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.dropout(self.attention(self.ln1(x)))\n",
    "        x = x + self.dropout(self.feedforward(self.ln2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the implementation of the `__init__` and `forward` functions of the full GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DziUiPi4WBD"
   },
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, d_in, d_out, context_length, num_heads, num_layers, dropout):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.embedding = nn.Embedding(vocab_size, d_in)\n",
    "        self.pos_embedding = nn.Embedding(context_length, d_out)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerLayer(\n",
    "                d_in=d_in, \n",
    "                d_out=d_out, \n",
    "                context_length=context_length, \n",
    "                num_heads=num_heads, \n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.ln_f = LayerNorm(d_out)\n",
    "        \n",
    "        self.lm_head = nn.Linear(d_out, vocab_size, bias=False)\n",
    "        \n",
    "        self.lm_head.weight = self.embedding.weight\n",
    "        \n",
    "        self.context_length = context_length\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "\n",
    "        token_embeddings = self.embedding(x)  \n",
    "        positions = torch.arange(0, seq_len, dtype=torch.long, device=x.device)\n",
    "        position_embeddings = self.pos_embedding(positions)  \n",
    "        x = token_embeddings + position_embeddings\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhZ8LGJJ3zw4"
   },
   "source": [
    "## Part 6: Data Preparation and Model Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, you have implemented the entire GPT model from scratch. Now it is time to implement the pretraining logic. This includes: data loading, data preparation, model pre-training and evaluation. In terms of pre-training data, you will need to use the Shakespeare dataset that can be found in `data/shakespeare.txt`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "In this last major part of the assignment, you will need to implement these steps: \n",
    "- Using `vocab.py` from Assignment 3 and the `subword_nmt` Python package, build a vocabulary of size at least `4000`.\n",
    "- Initialize a GPT model with your own choice of hyperparameters (_e.g._, number of layers, number of attention heads, hidden size dimension and so on). Note that the bigger the model the more compute you will need. For this reason, the model architecture is up to you.\n",
    "- The pre-training objective is _next token prediction_, when given a sequence $[w_1, w_2, ..., w_n]$ the model should predict the token $w_{n+1}$. This is important when preparing data into a proper format that can be fed to the model.\n",
    "- You will need to use the `F.cross_entropy` method provided by `pytorch` that calculates the cross-entropy loss.  \n",
    "- Use the AdamW optimizer to update the model's parameters. It can be imported from the `torch.optim.AdamW` package.\n",
    "- Implement the training loop that runs for at least $20K$ training steps.\n",
    "- Plot the training loss curve. You can do this after each specified number of steps or once the training finishes. However, the former strategy is recommended to monitor the training status of your model.\n",
    "- Run inference by feeding the model a prefix and see what tokens it can generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code goes here\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "from vocab import Vocab\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return [line.strip().lower() for line in f.readlines()]\n",
    "\n",
    "def build_vocabulary(data, vocab_size):\n",
    "    \n",
    "    with open('temp_bpe_codes.txt', 'w') as codes:\n",
    "        learn_bpe(data, codes, vocab_size)\n",
    "    \n",
    "    with open('temp_bpe_codes.txt', 'r') as codes:\n",
    "        bpe = BPE(codes)\n",
    "    \n",
    "    tokenized_data = [bpe.process_line(line) for line in data]\n",
    "    \n",
    "    vocab = Vocab.from_lines(tokenized_data)\n",
    "    \n",
    "    return vocab, bpe, tokenized_data\n",
    "\n",
    "def prepare_data(tokenized_data, vocab, context_length):\n",
    "\n",
    "    all_tokens = ' '.join(tokenized_data).split()\n",
    "    \n",
    "    token_indices = [vocab.token_to_ix.get(token, vocab.unk_ix) for token in all_tokens]\n",
    "    \n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, len(token_indices) - context_length):\n",
    "        inputs.append(token_indices[i:i + context_length])\n",
    "        targets.append(token_indices[i + 1:i + context_length + 1])\n",
    "    \n",
    "    return torch.tensor(inputs), torch.tensor(targets)\n",
    "\n",
    "def get_random_batch(inputs, targets, batch_size):\n",
    "        total_samples = inputs.shape[0]\n",
    "        \n",
    "        random_indices = torch.randperm(total_samples)[:batch_size]\n",
    "        \n",
    "        # Select random batch\n",
    "        batch_inputs = inputs[random_indices]\n",
    "        batch_targets = targets[random_indices]\n",
    "        \n",
    "        return batch_inputs, batch_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, targets):\n",
    "\n",
    "        batch_size, seq_len = targets.shape\n",
    "        mask = torch.zeros_like(targets, dtype=torch.bool)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "                eos_positions = (targets[i] == 1).nonzero(as_tuple=True)[0]\n",
    "                if len(eos_positions) > 0:\n",
    "                        first_eos_pos = eos_positions[0].item()\n",
    "                        mask[i, :first_eos_pos+1] = True\n",
    "                else:\n",
    "                        mask[i, :] = True\n",
    "\n",
    "        mask = mask.float()\n",
    "\n",
    "        logits_flat = logits.view(-1, logits.size(-1))\n",
    "        targets_flat = targets.view(-1)\n",
    "        mask_flat = mask.view(-1)\n",
    "\n",
    "        loss_per_token = F.cross_entropy(logits_flat, targets_flat, reduction='none')\n",
    "\n",
    "        masked_loss = loss_per_token * mask_flat\n",
    "\n",
    "        total_loss = masked_loss.sum()\n",
    "\n",
    "        total_tokens = mask.sum()\n",
    "\n",
    "        average_loss = total_loss / total_tokens\n",
    "\n",
    "        return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:02<00:00, 1970.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def train_gpt(model, inputs, targets, batch_size, lr, num_steps):\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    metrics = {'train_loss': []}\n",
    "    model.train()\n",
    "    pbar = tqdm(range(num_steps))\n",
    "    \n",
    "    for _ in pbar:\n",
    "        batch_inputs, batch_targets = get_random_batch(inputs, targets, batch_size)\n",
    "                \n",
    "        step = len(metrics['train_loss']) + 1\n",
    "        logits = model(batch_inputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = compute_loss(logits, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        metrics['train_loss'].append(loss.item())\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(metrics['train_loss'])\n",
    "            plt.xlabel('Steps')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Training Loss')\n",
    "            plt.show()\n",
    "            print(\"Mean Loss=%.3f\" % np.mean(metrics['train_loss'][-10:]))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "vocab_size = 5000\n",
    "context_length = 128\n",
    "d_in = 256\n",
    "d_out = 256\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "dropout = 0.1\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "num_steps = 22000\n",
    "\n",
    "data = load_data('data/shakespeare.txt')\n",
    "\n",
    "vocab, bpe, tokenized_data = build_vocabulary(data, vocab_size)\n",
    "\n",
    "inputs, targets = prepare_data(tokenized_data, vocab, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22000/22000 [10:16:24<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss=3.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPT(\n",
    "    vocab_size=len(vocab),\n",
    "    d_in=d_in,\n",
    "    d_out=d_out,\n",
    "    context_length=context_length,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "metrics = train_gpt(model, inputs, targets, batch_size, learning_rate, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, prefix, vocab, bpe, max_length=100, temperature=1.0):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    prefix_tokens = bpe.process_line(prefix.lower()).split()\n",
    "    input_ids = [vocab.token_to_ix.get(token, vocab.unk_ix) for token in prefix_tokens]\n",
    "    \n",
    "    if len(input_ids) > model.context_length:\n",
    "        input_ids = input_ids[-model.context_length:]\n",
    "    \n",
    "    while len(input_ids) < model.context_length:\n",
    "        input_ids.insert(0, vocab.bos_ix)\n",
    "    \n",
    "    input_tensor = torch.tensor([input_ids])\n",
    "    \n",
    "    generated_tokens = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            logits = model(input_tensor)\n",
    "            \n",
    "            next_token_logits = logits[0, -1, :] / temperature\n",
    "            \n",
    "            probs = F.softmax(next_token_logits, dim=-1)\n",
    "            \n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            \n",
    "            generated_tokens.append(next_token)\n",
    "            \n",
    "            # Stop if we generate EOS\n",
    "            if next_token == vocab.eos_ix:\n",
    "                break\n",
    "            \n",
    "            input_tensor = torch.cat([input_tensor[:, 1:], torch.tensor([[next_token]])], dim=1)\n",
    "    \n",
    "    generated_text = [vocab.tokens[token_id] for token_id in generated_tokens]\n",
    "    raw_text = ' '.join(generated_text)\n",
    "    # Remove BPE separator tokens\n",
    "    detokenized_text = raw_text.replace('@@ ', '')  \n",
    "    \n",
    "    return detokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated text with prefix 'Some are born great,':\n",
      "and words, well become your honour knowing; but virtuous love. tranio. gentlemen, like one sir valentine, you do with; if you say you do not love me, i shall find what you speak of her shall be your love. portia. you are instructed by this lineal. no, no, not a woman, and much dishonour in praise that cannot it to be certain, you are the matter to be remember'd to deny it. proteus. you were not so blasted than it is: the women moved, is to be\n"
     ]
    }
   ],
   "source": [
    "sample_prefixes = [\n",
    "    \"Some are born great,\"\n",
    "]\n",
    "\n",
    "for prefix in sample_prefixes:\n",
    "    generated = generate_text(model, prefix, vocab, bpe)\n",
    "    print(f\"\\nGenerated text with prefix '{prefix}':\")\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Remarks\n",
    "\n",
    "- You may use code snippets from previous assignments in this course. Many Python function/classes from A2 and A3 implement (or partially implement) what is required.\n",
    "- The choice of the pre-training hyperparameters such as the learning rate, batch size and such is up to you.\n",
    "- You are allowed to implement extra functions in the classes that you have completed in Part 1. This may be helpful especially when running inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "- Part 1: MSA /3  \n",
    "\t- Causal SA: /2  \n",
    "\t- MHA: /1  \n",
    "\n",
    "- Part 2: GELU: /1  \n",
    "- Part 3: LayerNorm /1.5  \n",
    "- Part 4: FeedForward: /1  \n",
    "- Part 5: Full GPT Model: /4:\n",
    "\t- Tansformer Layer: /2  \n",
    "\t- GPT Model: /2  \n",
    "\n",
    "Part 6: Data Preparation and Model Pretraining /2.5\n",
    "\n",
    "Total: /12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
